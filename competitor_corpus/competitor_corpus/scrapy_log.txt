2024-06-06 14:42:49 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: competitor_corpus)
2024-06-06 14:42:49 [scrapy.utils.log] INFO: Versions: lxml 5.2.2.0, libxml2 2.12.6, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.0, Twisted 24.3.0, Python 3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)], pyOpenSSL 24.1.0 (OpenSSL 3.2.2 4 Jun 2024), cryptography 42.0.8, Platform macOS-13.6.7-arm64-arm-64bit
2024-06-06 14:42:49 [root] INFO: Loaded start file
2024-06-06 14:42:49 [scrapy.addons] INFO: Enabled addons:
[]
2024-06-06 14:42:49 [scrapy.extensions.telnet] INFO: Telnet Password: 03c556050139fb12
2024-06-06 14:42:49 [py.warnings] WARNING: /Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/scrapy/extensions/feedexport.py:406: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2024-06-06 14:42:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-06-06 14:42:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'competitor_corpus',
 'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 20,
 'DOWNLOAD_DELAY': 2,
 'DOWNLOAD_TIMEOUT': 600,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_log.txt',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'competitor_corpus.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['competitor_corpus.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-06-06 14:42:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_zyte_smartproxy.ZyteSmartProxyMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-06-06 14:42:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-06-06 14:42:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-06-06 14:42:49 [scrapy.core.engine] INFO: Spider opened
2024-06-06 14:42:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-06-06 14:42:49 [scrapy_zyte_smartproxy.middleware] INFO: Using Zyte proxy service http://proxy.zyte.com:8011 with an API key ending in 5d10d14
2024-06-06 14:42:49 [scrapy_zyte_smartproxy.middleware] INFO: ZyteSmartProxyMiddleware: disabling download delays in Scrapy to optimize delays introduced by Zyte proxy services. To avoid this behaviour you can use the ZYTE_SMARTPROXY_PRESERVE_DELAY setting, but keep in mind that this may slow down the crawl significantly
2024-06-06 14:42:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-06-06 14:42:49 [root] INFO: Running start requests
2024-06-06 14:42:51 [root] INFO: Running parse_sitemap, this is the response: 200
2024-06-06 14:42:51 [root] INFO: Running this competitor: PostHog
2024-06-06 14:42:51 [scrapy.core.engine] INFO: Closing spider (finished)
2024-06-06 14:42:51 [root] INFO: Spider closed: finished
2024-06-06 14:42:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <function Spider.close at 0x106f48220>
Traceback (most recent call last):
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/scrapy/utils/defer.py", line 348, in maybeDeferred_coro
    result = f(*args, **kw)
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/scrapy/spiders/__init__.py", line 101, in close
    return cast(Union[Deferred, None], closed(reason))
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/competitor_corpus/competitor_corpus/spiders/crawl_sitemap.py", line 58, in closed
    with open('./3_logs/scrapy_log.txt', 'r') as log_file:
FileNotFoundError: [Errno 2] No such file or directory: './3_logs/scrapy_log.txt'
2024-06-06 14:42:51 [CrawlSitemap] INFO: Spider closed: CrawlSitemap
2024-06-06 14:42:51 [scrapy.extensions.feedexport] INFO: Stored csv feed (0 items) in: output_data.csv
2024-06-06 14:42:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 355,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 185738,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.18938,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 6, 6, 21, 42, 51, 136850, tzinfo=datetime.timezone.utc),
 'log_count/ERROR': 1,
 'log_count/INFO': 18,
 'log_count/WARNING': 1,
 'memusage/max': 67141632,
 'memusage/startup': 67141632,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 6, 6, 21, 42, 49, 947470, tzinfo=datetime.timezone.utc),
 'zyte_smartproxy/delay/reset_backoff': 1,
 'zyte_smartproxy/request': 1,
 'zyte_smartproxy/request/method/GET': 1,
 'zyte_smartproxy/response': 1,
 'zyte_smartproxy/response/status/200': 1}
2024-06-06 14:42:51 [scrapy.core.engine] INFO: Spider closed (finished)
2024-06-06 14:44:10 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: competitor_corpus)
2024-06-06 14:44:10 [scrapy.utils.log] INFO: Versions: lxml 5.2.2.0, libxml2 2.12.6, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.0, Twisted 24.3.0, Python 3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)], pyOpenSSL 24.1.0 (OpenSSL 3.2.2 4 Jun 2024), cryptography 42.0.8, Platform macOS-13.6.7-arm64-arm-64bit
2024-06-06 14:44:10 [root] INFO: Getting files: /Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/competitor_corpus/competitor_corpus
2024-06-06 14:44:10 [root] INFO: Loaded start file
2024-06-06 14:44:10 [scrapy.addons] INFO: Enabled addons:
[]
2024-06-06 14:44:10 [scrapy.extensions.telnet] INFO: Telnet Password: 214e601fc84bf7f9
2024-06-06 14:44:10 [py.warnings] WARNING: /Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/scrapy/extensions/feedexport.py:406: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2024-06-06 14:44:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-06-06 14:44:10 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'competitor_corpus',
 'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 20,
 'DOWNLOAD_DELAY': 2,
 'DOWNLOAD_TIMEOUT': 600,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_log.txt',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'competitor_corpus.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['competitor_corpus.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-06-06 14:44:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_zyte_smartproxy.ZyteSmartProxyMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-06-06 14:44:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-06-06 14:44:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-06-06 14:44:10 [scrapy.core.engine] INFO: Spider opened
2024-06-06 14:44:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-06-06 14:44:10 [scrapy_zyte_smartproxy.middleware] INFO: Using Zyte proxy service http://proxy.zyte.com:8011 with an API key ending in 5d10d14
2024-06-06 14:44:10 [scrapy_zyte_smartproxy.middleware] INFO: ZyteSmartProxyMiddleware: disabling download delays in Scrapy to optimize delays introduced by Zyte proxy services. To avoid this behaviour you can use the ZYTE_SMARTPROXY_PRESERVE_DELAY setting, but keep in mind that this may slow down the crawl significantly
2024-06-06 14:44:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-06-06 14:44:10 [root] INFO: Running start requests
2024-06-06 14:44:12 [root] INFO: Running parse_sitemap, this is the response: 200
2024-06-06 14:44:12 [root] INFO: Running this competitor: PostHog
2024-06-06 14:44:12 [scrapy.core.engine] INFO: Closing spider (finished)
2024-06-06 14:44:12 [root] INFO: Spider closed: finished
2024-06-06 14:44:12 [scrapy.utils.signal] ERROR: Error caught on signal handler: <function Spider.close at 0x102800220>
Traceback (most recent call last):
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/scrapy/utils/defer.py", line 348, in maybeDeferred_coro
    result = f(*args, **kw)
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/scrapy/spiders/__init__.py", line 101, in close
    return cast(Union[Deferred, None], closed(reason))
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/competitor_corpus/competitor_corpus/spiders/crawl_sitemap.py", line 58, in closed
    with open('./3_logs/scrapy_log.txt', 'r') as log_file:
FileNotFoundError: [Errno 2] No such file or directory: './3_logs/scrapy_log.txt'
2024-06-06 14:44:12 [CrawlSitemap] INFO: Spider closed: CrawlSitemap
2024-06-06 14:44:12 [scrapy.extensions.feedexport] INFO: Stored csv feed (0 items) in: output_data.csv
2024-06-06 14:44:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 355,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 185734,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 1.273799,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 6, 6, 21, 44, 12, 237369, tzinfo=datetime.timezone.utc),
 'log_count/ERROR': 1,
 'log_count/INFO': 18,
 'log_count/WARNING': 1,
 'memusage/max': 67321856,
 'memusage/startup': 67321856,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 6, 6, 21, 44, 10, 963570, tzinfo=datetime.timezone.utc),
 'zyte_smartproxy/delay/reset_backoff': 1,
 'zyte_smartproxy/request': 1,
 'zyte_smartproxy/request/method/GET': 1,
 'zyte_smartproxy/response': 1,
 'zyte_smartproxy/response/status/200': 1}
2024-06-06 14:44:12 [scrapy.core.engine] INFO: Spider closed (finished)
2024-06-06 14:47:57 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: competitor_corpus)
2024-06-06 14:47:57 [scrapy.utils.log] INFO: Versions: lxml 5.2.2.0, libxml2 2.12.6, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.0, Twisted 24.3.0, Python 3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)], pyOpenSSL 24.1.0 (OpenSSL 3.2.2 4 Jun 2024), cryptography 42.0.8, Platform macOS-13.6.7-arm64-arm-64bit
2024-06-06 14:47:57 [root] INFO: Getting files: /Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/competitor_corpus/competitor_corpus
2024-06-06 14:47:57 [root] INFO: Loaded start file
2024-06-06 14:47:57 [scrapy.addons] INFO: Enabled addons:
[]
2024-06-06 14:47:57 [scrapy.extensions.telnet] INFO: Telnet Password: 394182a8b6653eac
2024-06-06 14:47:57 [py.warnings] WARNING: /Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/scrapy/extensions/feedexport.py:406: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
  exporter = cls(crawler)

2024-06-06 14:47:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2024-06-06 14:47:57 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'competitor_corpus',
 'CONCURRENT_REQUESTS': 32,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 20,
 'DOWNLOAD_DELAY': 2,
 'DOWNLOAD_TIMEOUT': 600,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_log.txt',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'competitor_corpus.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_TIMES': 3,
 'SPIDER_MODULES': ['competitor_corpus.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-06-06 14:47:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy_zyte_smartproxy.ZyteSmartProxyMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-06-06 14:47:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-06-06 14:47:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2024-06-06 14:47:57 [scrapy.core.engine] INFO: Spider opened
2024-06-06 14:47:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-06-06 14:47:57 [scrapy_zyte_smartproxy.middleware] INFO: Using Zyte proxy service http://proxy.zyte.com:8011 with an API key ending in 5d10d14
2024-06-06 14:47:57 [scrapy_zyte_smartproxy.middleware] INFO: ZyteSmartProxyMiddleware: disabling download delays in Scrapy to optimize delays introduced by Zyte proxy services. To avoid this behaviour you can use the ZYTE_SMARTPROXY_PRESERVE_DELAY setting, but keep in mind that this may slow down the crawl significantly
2024-06-06 14:47:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-06-06 14:47:57 [root] INFO: Running start requests
2024-06-06 14:47:58 [root] INFO: Running parse_sitemap, this is the response: 200
2024-06-06 14:47:58 [root] INFO: Running this competitor: PostHog
2024-06-06 14:47:58 [scrapy.core.engine] INFO: Closing spider (finished)
2024-06-06 14:47:58 [root] INFO: Spider closed: finished
2024-06-06 14:47:58 [scrapy.utils.signal] ERROR: Error caught on signal handler: <function Spider.close at 0x1026b8220>
Traceback (most recent call last):
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/scrapy/utils/defer.py", line 348, in maybeDeferred_coro
    result = f(*args, **kw)
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/pydispatch/robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/venv/lib/python3.11/site-packages/scrapy/spiders/__init__.py", line 101, in close
    return cast(Union[Deferred, None], closed(reason))
  File "/Users/ianito/DevProjects/competitor_weekly_v1/competitor-weekly-v1/competitor_corpus/competitor_corpus/spiders/crawl_sitemap.py", line 60, in closed
    logs = self.log_handler.get_logs()
AttributeError: 'CrawlSitemap' object has no attribute 'log_handler'
2024-06-06 14:47:58 [scrapy.extensions.feedexport] INFO: Stored csv feed (0 items) in: output_data.csv
2024-06-06 14:47:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 355,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 185737,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.829618,
 'feedexport/success_count/FileFeedStorage': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2024, 6, 6, 21, 47, 58, 540781, tzinfo=datetime.timezone.utc),
 'log_count/ERROR': 1,
 'log_count/INFO': 17,
 'log_count/WARNING': 1,
 'memusage/max': 66797568,
 'memusage/startup': 66797568,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2024, 6, 6, 21, 47, 57, 711163, tzinfo=datetime.timezone.utc),
 'zyte_smartproxy/delay/reset_backoff': 1,
 'zyte_smartproxy/request': 1,
 'zyte_smartproxy/request/method/GET': 1,
 'zyte_smartproxy/response': 1,
 'zyte_smartproxy/response/status/200': 1}
2024-06-06 14:47:58 [scrapy.core.engine] INFO: Spider closed (finished)
